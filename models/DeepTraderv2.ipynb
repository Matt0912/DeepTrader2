{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "## V2 CREATED AFTER 2 BEST TRADERS DIDN'T PERFORM WELL\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1   2      3           4           5           6       7           8   \\\n",
      "0   2.2000   0  138.0 -138.000000   69.000000    0.100000  138.10    0.200000   \n",
      "1   4.6125   0   72.0  570.050000  421.025000  421.025000  136.00  706.050000   \n",
      "2   5.9250   0   61.0   19.000000  112.000000  112.000000  103.00  122.000000   \n",
      "3   6.8625   1   97.0    7.937037   88.968519   90.291358   85.00   92.937037   \n",
      "4   7.6875   0   58.0   36.000000  103.000000  109.000000   85.00  121.000000   \n",
      "5  11.2500   1   92.0    1.000000   90.000000   90.000000   90.00   91.000000   \n",
      "6  12.5375   1  136.0    6.666667  103.333333  103.333333  100.00  106.666667   \n",
      "7  13.2125   1  115.0    5.000000  110.000000  110.000000  108.00  113.000000   \n",
      "8  13.6625   0  113.0    0.750000  113.625000  113.625000  113.25  114.000000   \n",
      "9  15.4625   0  112.0    1.000000  112.000000  112.000000  112.00  113.000000   \n",
      "\n",
      "       9   10  11          12        13          14  \n",
      "0  2.2000   1   3    0.300000  0.400000  138.200000  \n",
      "1  2.4125   0   7  138.000000  0.000000  136.000000  \n",
      "2  1.3125   0   8  137.000000  0.005161  103.000000  \n",
      "3  0.9375   0   8  125.666667  0.076954   92.937037  \n",
      "4  0.8250   0   8  117.484259  0.125438   85.000000  \n",
      "5  3.5625  -1  13  114.124100  0.137873   91.000000  \n",
      "6  1.2875  -1  15  103.941076  0.215559  106.666667  \n",
      "7  0.6750   0  18   95.679308  0.287089  113.000000  \n",
      "8  0.4500   0  19   96.468056  0.259934  113.250000  \n",
      "9  1.8000   0  23  100.114851  0.210426  112.000000  \n",
      "0    32\n",
      "1     8\n",
      "2    20\n",
      "3    42\n",
      "4    41\n",
      "5    31\n",
      "6     1\n",
      "7    39\n",
      "8    16\n",
      "9     9\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_data = pd.read_csv('result.csv', header=None)\n",
    "trader_ranks = full_data[full_data.columns[0]]\n",
    "data = full_data.drop(full_data.columns[0], axis=1)\n",
    "\n",
    "print(data.head(10))\n",
    "print(trader_ranks.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalise data and convert ranks in to weights (using reciprocal function)\n",
    "def reciprocal(x):\n",
    "    return float(1/x)\n",
    "\n",
    "normalised_data=(data-data.min())/(data.max()-data.min())\n",
    "trader_ranks_frame = trader_ranks.to_frame()\n",
    "trader_weights = trader_ranks_frame.applymap(reciprocal)\n",
    "\n",
    "# print(normalised_data.head(10))\n",
    "# print(trader_weights.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.031250\n",
      "1          0.125000\n",
      "2          0.050000\n",
      "3          0.023810\n",
      "4          0.024390\n",
      "             ...   \n",
      "4250099    0.125000\n",
      "4250100    0.058824\n",
      "4250101    0.250000\n",
      "4250102    0.023256\n",
      "4250103    0.040000\n",
      "Name: 0, Length: 4250104, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "\n",
    "validation_split = 0.1\n",
    "train, validation = train_test_split(normalised_data, test_size=validation_split, shuffle=False)\n",
    "train_trader_weights, val_trader_weights = train_test_split(trader_weights, test_size=validation_split, shuffle=False)\n",
    "\n",
    "print(train_trader_weights[0])\n",
    "\n",
    "train_x = train.loc[:, :13]\n",
    "train_y = train.loc[:, 14]\n",
    "val_x = validation.loc[:, :13]\n",
    "val_y = validation.loc[:, 14]\n",
    "\n",
    "x_train = train_x.to_numpy()\n",
    "y_train = train_y.to_numpy()\n",
    "x_val = val_x.to_numpy()\n",
    "y_val = val_y.to_numpy()\n",
    "\n",
    "x_train = x_train[:,:, newaxis]\n",
    "x_val = x_val[:,:, newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 4250104 samples, validate on 472234 samples\n",
      "Epoch 1/10\n",
      "4250104/4250104 [==============================] - 33s 8us/sample - loss: 0.0016 - val_loss: 0.0070\n",
      "Epoch 2/10\n",
      "4250104/4250104 [==============================] - 30s 7us/sample - loss: 6.2442e-04 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "4250104/4250104 [==============================] - 30s 7us/sample - loss: 4.3000e-04 - val_loss: 0.0036\n",
      "Epoch 4/10\n",
      "4250104/4250104 [==============================] - 34s 8us/sample - loss: 3.4449e-04 - val_loss: 0.0032\n",
      "Epoch 5/10\n",
      "4250104/4250104 [==============================] - 32s 8us/sample - loss: 3.0345e-04 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "4250104/4250104 [==============================] - 31s 7us/sample - loss: 2.8398e-04 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "4250104/4250104 [==============================] - 39s 9us/sample - loss: 2.7307e-04 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "4250104/4250104 [==============================] - 33s 8us/sample - loss: 2.6483e-04 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "4250104/4250104 [==============================] - 30s 7us/sample - loss: 2.5734e-04 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "4250104/4250104 [==============================] - 30s 7us/sample - loss: 2.4958e-04 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM\n",
    "#from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(x_train.shape[1:]), return_sequences=False))\n",
    "#model.add(Dropout(0.05))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=1.5e-4, decay=1e-6)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=1024, validation_data=(x_val, y_val), sample_weight=train_trader_weights[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64067936 0.03125    0.882     ]\n",
      " [0.71089059 0.125      0.86      ]\n",
      " [0.58541602 0.05       0.53      ]\n",
      " [0.44821984 0.02380952 0.42937037]\n",
      " [0.41523713 0.02439024 0.35      ]\n",
      " [0.42404094 0.03225806 0.41      ]\n",
      " [0.58678889 1.         0.56666667]\n",
      " [0.61659241 0.02564103 0.63      ]\n",
      " [0.63078588 0.0625     0.6325    ]\n",
      " [0.61043739 0.11111111 0.62      ]\n",
      " [0.62256652 0.33333333 0.62      ]\n",
      " [0.50799012 0.09090909 0.52      ]\n",
      " [0.54480618 0.04       0.4792037 ]\n",
      " [0.46041343 0.04347826 0.46      ]\n",
      " [0.57034051 0.05263158 0.61      ]\n",
      " [0.65117431 0.03333333 0.64      ]\n",
      " [0.39795619 0.01960784 0.41      ]\n",
      " [0.37666428 0.1        0.38      ]\n",
      " [0.46587855 0.5        0.5       ]\n",
      " [0.49959278 0.02777778 0.53466667]\n",
      " [0.47231752 0.01785714 0.49      ]\n",
      " [0.5093196  0.04166667 0.52633333]\n",
      " [0.41268504 0.02777778 0.42      ]\n",
      " [0.35449842 0.08333333 0.36      ]\n",
      " [0.42903692 0.05882353 0.45      ]\n",
      " [0.49131641 0.05263158 0.5       ]\n",
      " [0.56176543 0.2        0.59      ]\n",
      " [0.37804741 0.03225806 0.42      ]\n",
      " [0.33082312 0.02941176 0.38      ]\n",
      " [0.31065917 0.02083333 0.35      ]\n",
      " [0.43218902 0.0625     0.36      ]\n",
      " [0.31468019 0.05       0.35      ]\n",
      " [0.41618949 0.16666667 0.38      ]\n",
      " [0.33777952 0.09090909 0.37      ]\n",
      " [0.32058015 0.02       0.36      ]\n",
      " [0.43904358 0.25       0.39      ]\n",
      " [0.39393175 0.0212766  0.41555556]\n",
      " [0.46675882 0.03703704 0.42555556]\n",
      " [0.39629251 0.04545455 0.44      ]\n",
      " [0.38983458 0.02040816 0.42      ]\n",
      " [0.45220694 1.         0.39      ]\n",
      " [0.32139775 0.01960784 0.36      ]\n",
      " [0.39267942 0.02564103 0.39      ]\n",
      " [0.31780982 0.07692308 0.36      ]\n",
      " [0.42268801 0.02439024 0.38      ]\n",
      " [0.35395235 0.5        0.4       ]\n",
      " [0.35444182 0.03030303 0.39      ]\n",
      " [0.51704657 0.125      0.48      ]\n",
      " [0.44781828 0.08333333 0.48      ]\n",
      " [0.44454458 0.25       0.42316667]\n",
      " [0.51525247 1.         0.49      ]\n",
      " [0.53704131 0.03703704 0.51      ]\n",
      " [0.52715379 0.03030303 0.55      ]\n",
      " [0.61274743 0.01960784 0.59      ]\n",
      " [0.59747732 0.01724138 0.62727778]\n",
      " [0.65749747 0.09090909 0.66      ]\n",
      " [0.68589008 0.02702703 0.69      ]\n",
      " [0.68464965 0.14285714 0.68666667]\n",
      " [0.70554543 0.025      0.71      ]\n",
      " [0.71718311 0.04761905 0.72      ]\n",
      " [0.59426522 0.02222222 0.57298765]\n",
      " [0.61259639 0.14285714 0.60148148]\n",
      " [0.57704192 0.07692308 0.57      ]\n",
      " [0.57643008 0.06666667 0.57      ]\n",
      " [0.57885146 0.2        0.58      ]\n",
      " [0.5365653  0.02173913 0.54      ]\n",
      " [0.52031851 0.33333333 0.53      ]\n",
      " [0.52225035 0.03448276 0.52473251]\n",
      " [0.47476187 0.05263158 0.49      ]\n",
      " [0.53576362 0.05555556 0.55      ]\n",
      " [0.55010545 0.33333333 0.56      ]\n",
      " [0.58771795 0.04545455 0.57      ]\n",
      " [0.51504344 0.05882353 0.52133333]\n",
      " [0.61122477 0.02857143 0.6       ]\n",
      " [0.47174937 0.1        0.48      ]\n",
      " [0.46857059 0.01470588 0.48      ]\n",
      " [0.44792074 0.11111111 0.46      ]\n",
      " [0.48556066 0.16666667 0.46      ]\n",
      " [0.43059668 0.0212766  0.45      ]\n",
      " [0.41842312 0.01923077 0.44      ]\n",
      " [0.39084661 0.07142857 0.41      ]\n",
      " [0.39180529 0.07692308 0.41      ]\n",
      " [0.37204111 0.02040816 0.39      ]\n",
      " [0.47171366 0.07142857 0.41320988]\n",
      " [0.38705882 0.05       0.41      ]\n",
      " [0.45037389 1.         0.4204227 ]\n",
      " [0.45177001 0.04545455 0.47      ]\n",
      " [0.4629873  0.02631579 0.48      ]\n",
      " [0.5347026  0.01639344 0.53      ]\n",
      " [0.59321541 0.14285714 0.5755    ]\n",
      " [0.62189156 0.5        0.61      ]\n",
      " [0.58451664 0.08333333 0.57027778]\n",
      " [0.53578341 0.5        0.52      ]\n",
      " [0.66058242 0.03030303 0.65      ]\n",
      " [0.5383597  0.09090909 0.53      ]\n",
      " [0.46983832 0.02777778 0.46      ]\n",
      " [0.4123503  0.02272727 0.4       ]\n",
      " [0.52407736 0.03125    0.51816667]\n",
      " [0.59904766 0.25       0.59      ]\n",
      " [0.63989776 0.06666667 0.62      ]]\n",
      "[[0.60668093 1.         0.62      ]\n",
      " [0.60121799 0.04761905 0.61      ]\n",
      " [0.58637607 0.2        0.6       ]\n",
      " [0.61327612 0.1        0.6       ]\n",
      " [0.60477948 0.03571429 0.6       ]\n",
      " [0.5560084  0.07142857 0.56      ]\n",
      " [0.54625863 0.05882353 0.55      ]\n",
      " [0.53278959 0.125      0.53      ]\n",
      " [0.52287894 0.33333333 0.52      ]\n",
      " [0.4992542  0.04347826 0.51      ]\n",
      " [0.51146251 0.11111111 0.49      ]\n",
      " [0.50774562 0.06666667 0.49      ]\n",
      " [0.49522746 0.0625     0.49      ]\n",
      " [0.55676609 0.02631579 0.56      ]\n",
      " [0.47783279 0.02702703 0.47      ]\n",
      " [0.48286235 0.02439024 0.49      ]\n",
      " [0.47214571 0.03225806 0.48      ]\n",
      " [0.43755496 0.04545455 0.47      ]\n",
      " [0.48002648 0.5        0.47      ]\n",
      " [0.48023623 0.03846154 0.46      ]\n",
      " [0.41820204 0.04761905 0.42      ]\n",
      " [0.51665699 0.03030303 0.52      ]\n",
      " [0.40164021 1.         0.41      ]\n",
      " [0.35228348 0.07692308 0.32      ]\n",
      " [0.38475585 0.02564103 0.43      ]\n",
      " [0.39906213 0.04347826 0.41      ]\n",
      " [0.48807228 0.25       0.48      ]\n",
      " [0.47639599 0.05       0.47      ]\n",
      " [0.38672078 0.33333333 0.39      ]\n",
      " [0.32626939 0.06666667 0.37      ]\n",
      " [0.41434157 0.05263158 0.39      ]\n",
      " [0.34683451 0.14285714 0.38      ]\n",
      " [0.33148548 0.01639344 0.38      ]\n",
      " [0.32919717 0.125      0.36      ]\n",
      " [0.43386227 0.05555556 0.39      ]\n",
      " [0.45419341 0.03571429 0.45      ]\n",
      " [0.58110631 0.0625     0.58      ]\n",
      " [0.39006841 0.02173913 0.38      ]\n",
      " [0.3741287  0.04       0.36      ]\n",
      " [0.32767731 0.25       0.37      ]\n",
      " [0.39460349 0.02564103 0.33      ]\n",
      " [0.34537244 0.07692308 0.33      ]\n",
      " [0.60245377 0.14285714 0.61      ]\n",
      " [0.60748458 0.06666667 0.63      ]\n",
      " [0.63411868 0.01666667 0.63      ]\n",
      " [0.6326381  0.125      0.62      ]\n",
      " [0.5425843  1.         0.53      ]\n",
      " [0.40927511 0.33333333 0.38      ]\n",
      " [0.41350877 0.02941176 0.39      ]\n",
      " [0.4152137  0.05882353 0.38      ]\n",
      " [0.63981014 0.1        0.66      ]\n",
      " [0.65925163 0.16666667 0.68      ]\n",
      " [0.72714794 0.08333333 0.71      ]\n",
      " [0.60918468 0.04166667 0.59      ]\n",
      " [0.63130522 0.16666667 0.64      ]\n",
      " [0.6233418  0.5        0.62      ]\n",
      " [0.61153853 0.2        0.61      ]\n",
      " [0.59591413 0.03571429 0.61      ]\n",
      " [0.59909189 0.14285714 0.6       ]\n",
      " [0.56422985 0.04       0.55      ]\n",
      " [0.54200119 0.05263158 0.53      ]\n",
      " [0.65287465 0.09090909 0.66      ]\n",
      " [0.55136287 0.02040816 0.51      ]\n",
      " [0.69243276 0.03703704 0.7       ]\n",
      " [0.51070291 0.04761905 0.48      ]\n",
      " [0.53915685 0.03125    0.5       ]\n",
      " [0.70778877 0.16666667 0.73      ]\n",
      " [0.52235949 0.02777778 0.48      ]\n",
      " [0.50486004 0.2        0.46      ]\n",
      " [0.49373949 0.03030303 0.45      ]\n",
      " [0.46599102 0.01470588 0.42      ]\n",
      " [0.7214815  0.11111111 0.71      ]\n",
      " [0.7306596  0.03225806 0.75      ]\n",
      " [0.67281252 0.05263158 0.67      ]\n",
      " [0.55081862 0.07142857 0.54      ]\n",
      " [0.54076314 0.05555556 0.53      ]\n",
      " [0.64291877 0.02631579 0.64      ]\n",
      " [0.65462214 0.1        0.66      ]\n",
      " [0.5282225  0.0625     0.52      ]\n",
      " [0.68053776 0.5        0.65      ]\n",
      " [0.69334871 0.03225806 0.68      ]\n",
      " [0.7216205  0.125      0.7       ]\n",
      " [0.68891442 0.07692308 0.68      ]\n",
      " [0.68464804 0.04166667 0.68      ]\n",
      " [0.63834941 1.         0.64      ]\n",
      " [0.60567862 0.01449275 0.59      ]\n",
      " [0.5355863  0.125      0.52      ]\n",
      " [0.70530468 0.1        0.68      ]\n",
      " [0.52270538 0.05263158 0.47      ]\n",
      " [0.7119773  0.16666667 0.71      ]\n",
      " [0.6608091  0.02702703 0.67      ]\n",
      " [0.51113945 0.25       0.47      ]\n",
      " [0.69730568 0.11111111 0.69      ]\n",
      " [0.49195147 0.02941176 0.45      ]\n",
      " [0.63223827 0.14285714 0.63      ]\n",
      " [0.59604877 0.0625     0.58      ]\n",
      " [0.51659101 0.05882353 0.53      ]\n",
      " [0.52935088 0.07142857 0.53      ]\n",
      " [0.48679638 0.03030303 0.5       ]\n",
      " [0.48685426 0.02272727 0.48      ]]\n"
     ]
    }
   ],
   "source": [
    "## Previous loss: loss: 2.1564e-04 - val_loss: 0.0016\n",
    "## 512, 1e-4, no dropout, no weights = loss: 8.8952e-04 - val_loss: 9.5390e-04\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "train_values = x_train[:100]\n",
    "print(np.c_[model.predict(train_values), train_trader_weights[:100], y_train[:100]])\n",
    "test_values = x_val[:100]\n",
    "print(np.c_[model.predict(test_values), val_trader_weights[:100], y_val[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('DeepTraderv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472234/472234 [==============================] - 67s 141us/sample - loss: 9.5390e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0009539012649751713"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('DeepTraderv2_no_weights.h5')\n",
    "\n",
    "new_model.evaluate(x_val,  y_val, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472234, 13, 1)\n",
      "[[[0.22351224]\n",
      "  [0.        ]\n",
      "  [0.22      ]\n",
      "  [0.14013778]\n",
      "  [0.16181818]\n",
      "  [0.15921788]\n",
      "  [0.74666667]\n",
      "  [0.116     ]\n",
      "  [0.00424328]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.70322874]\n",
      "  [0.13223405]]\n",
      "\n",
      " [[0.22511123]\n",
      "  [0.        ]\n",
      "  [0.33      ]\n",
      "  [0.14104776]\n",
      "  [0.16      ]\n",
      "  [0.15782123]\n",
      "  [0.74      ]\n",
      "  [0.116     ]\n",
      "  [0.01084394]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.71649077]\n",
      "  [0.11900353]]]\n",
      "[[[0.22351224]\n",
      "  [0.        ]\n",
      "  [0.22      ]\n",
      "  [0.14013778]\n",
      "  [0.16181818]\n",
      "  [0.15921788]\n",
      "  [0.74666667]\n",
      "  [0.116     ]\n",
      "  [0.00424328]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.70322874]\n",
      "  [0.13223405]]\n",
      "\n",
      " [[0.22511123]\n",
      "  [0.        ]\n",
      "  [0.33      ]\n",
      "  [0.14104776]\n",
      "  [0.16      ]\n",
      "  [0.15782123]\n",
      "  [0.74      ]\n",
      "  [0.116     ]\n",
      "  [0.01084394]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.71649077]\n",
      "  [0.11900353]]]\n",
      "[[[0.98991935]\n",
      "  [0.        ]\n",
      "  [0.22      ]\n",
      "  [0.14013778]\n",
      "  [0.16181818]\n",
      "  [0.15921788]\n",
      "  [0.74666667]\n",
      "  [0.116     ]\n",
      "  [0.00424328]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.70322874]\n",
      "  [0.13223405]]\n",
      "\n",
      " [[0.94382647]\n",
      "  [0.        ]\n",
      "  [0.33      ]\n",
      "  [0.14104776]\n",
      "  [0.16      ]\n",
      "  [0.15782123]\n",
      "  [0.74      ]\n",
      "  [0.116     ]\n",
      "  [0.01084394]\n",
      "  [0.        ]\n",
      "  [0.609375  ]\n",
      "  [0.71649077]\n",
      "  [0.11900353]]]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.copy(x_val)\n",
    "print(test_arr.shape)\n",
    "print(test_arr[:2, :, :])\n",
    "np.random.shuffle(test_arr[:,0])\n",
    "print(x_val[:2, :, :])\n",
    "print(test_arr[:2, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
